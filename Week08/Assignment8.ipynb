{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 8\n",
    "## Shovan Biswas: Team (Shovan Biswas, Randy Thompson, Benjamin Horvath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short description of the database\n",
    "\n",
    "NLTK includes a small selection of texts from the Project Gutenberg electronic text archive, which contains some 25,000 free electronic books, hosted at http://www.gutenberg.org/, from which we selected Lewis Carroll's _Alice in the Wonderland_. We begin by getting the Python interpreter to load the NLTK package, then use nltk.corpus.gutenberg.words(), to load the words:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages  \n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk as nltk\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the selected corpus, which is Lewis Carroll's _Alice in Wonderland_. The text is already tokenized, but it seems like there are artifacts from the Gutenberg Project remaining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Alice',\n",
       " \"'\",\n",
       " 's',\n",
       " 'Adventures',\n",
       " 'in',\n",
       " 'Wonderland',\n",
       " 'by',\n",
       " 'Lewis',\n",
       " 'Carroll',\n",
       " '1865',\n",
       " ']',\n",
       " 'CHAPTER',\n",
       " 'I',\n",
       " '.',\n",
       " 'Down',\n",
       " 'the',\n",
       " 'Rabbit',\n",
       " '-',\n",
       " 'Hole']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carroll = nltk.corpus.gutenberg.words('carroll-alice.txt')\n",
    "carroll[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of unique tokens\n",
    "\n",
    "To get the number of unique words in the corpus, we will have to filter out the puncuation tokens and handle capital letters. A simple list comprehension combined with the `string` package's list of punctuation should be sufficient. (We'll also need to get rid of orphaned es's and tee's and blanks.) From there, it's easy to find the number of unique words in the text by converting the list to a set and getting its size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alice',\n",
       " 'adventures',\n",
       " 'in',\n",
       " 'wonderland',\n",
       " 'by',\n",
       " 'lewis',\n",
       " 'carroll',\n",
       " '1865',\n",
       " 'chapter',\n",
       " 'i',\n",
       " 'down',\n",
       " 'the',\n",
       " 'rabbit',\n",
       " 'hole',\n",
       " 'alice',\n",
       " 'was',\n",
       " 'beginning',\n",
       " 'to',\n",
       " 'get',\n",
       " 'very',\n",
       " 'tired',\n",
       " 'of',\n",
       " 'sitting',\n",
       " 'by',\n",
       " 'her',\n",
       " 'sister',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bank',\n",
       " 'and',\n",
       " 'of',\n",
       " 'having',\n",
       " 'nothing',\n",
       " 'to',\n",
       " 'do',\n",
       " 'once',\n",
       " 'or',\n",
       " 'twice',\n",
       " 'she',\n",
       " 'had',\n",
       " 'peeped',\n",
       " 'into',\n",
       " 'the',\n",
       " 'book',\n",
       " 'her',\n",
       " 'sister',\n",
       " 'was',\n",
       " 'reading',\n",
       " 'but',\n",
       " 'it',\n",
       " 'had',\n",
       " 'no',\n",
       " 'pictures',\n",
       " 'or',\n",
       " 'conversations',\n",
       " 'in',\n",
       " 'it',\n",
       " 'and',\n",
       " 'what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'a',\n",
       " 'book',\n",
       " 'thought',\n",
       " 'alice',\n",
       " 'without',\n",
       " 'pictures',\n",
       " 'or',\n",
       " 'conversation',\n",
       " 'so',\n",
       " 'she',\n",
       " 'was',\n",
       " 'considering',\n",
       " 'in',\n",
       " 'her',\n",
       " 'own',\n",
       " 'mind',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'she',\n",
       " 'could',\n",
       " 'for',\n",
       " 'the',\n",
       " 'hot',\n",
       " 'day',\n",
       " 'made',\n",
       " 'her',\n",
       " 'feel',\n",
       " 'very',\n",
       " 'sleepy',\n",
       " 'and',\n",
       " 'stupid',\n",
       " 'whether',\n",
       " 'the',\n",
       " 'pleasure',\n",
       " 'of']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carroll_uniq = [token.strip(string.punctuation).lower() for token in carroll]\n",
    "carroll_uniq = [token for token in carroll_uniq if token not in ['', 's', 't']]\n",
    "\n",
    "carroll_uniq[0:99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the numbers of tokens and unique tokens are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2568"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(carroll_uniq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26917"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(carroll_uniq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many unique words make up half of the corpus?\n",
    "\n",
    "To answer this we have to first count the frequency of each token. This is pretty easy with Python's built-in `Counter` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'alice': 398,\n",
       "         'adventures': 7,\n",
       "         'in': 369,\n",
       "         'wonderland': 3,\n",
       "         'by': 59,\n",
       "         'lewis': 1,\n",
       "         'carroll': 1,\n",
       "         '1865': 1,\n",
       "         'chapter': 12,\n",
       "         'i': 545,\n",
       "         'down': 102,\n",
       "         'the': 1642,\n",
       "         'rabbit': 51,\n",
       "         'hole': 5,\n",
       "         'was': 357,\n",
       "         'beginning': 14,\n",
       "         'to': 729,\n",
       "         'get': 46,\n",
       "         'very': 144,\n",
       "         'tired': 7,\n",
       "         'of': 514,\n",
       "         'sitting': 10,\n",
       "         'her': 248,\n",
       "         'sister': 9,\n",
       "         'on': 193,\n",
       "         'bank': 3,\n",
       "         'and': 872,\n",
       "         'having': 10,\n",
       "         'nothing': 34,\n",
       "         'do': 81,\n",
       "         'once': 34,\n",
       "         'or': 77,\n",
       "         'twice': 5,\n",
       "         'she': 553,\n",
       "         'had': 178,\n",
       "         'peeped': 3,\n",
       "         'into': 67,\n",
       "         'book': 11,\n",
       "         'reading': 3,\n",
       "         'but': 170,\n",
       "         'it': 595,\n",
       "         'no': 90,\n",
       "         'pictures': 4,\n",
       "         'conversations': 1,\n",
       "         'what': 141,\n",
       "         'is': 108,\n",
       "         'use': 18,\n",
       "         'a': 632,\n",
       "         'thought': 74,\n",
       "         'without': 26,\n",
       "         'conversation': 10,\n",
       "         'so': 151,\n",
       "         'considering': 3,\n",
       "         'own': 10,\n",
       "         'mind': 11,\n",
       "         'as': 263,\n",
       "         'well': 63,\n",
       "         'could': 77,\n",
       "         'for': 153,\n",
       "         'hot': 7,\n",
       "         'day': 29,\n",
       "         'made': 30,\n",
       "         'feel': 8,\n",
       "         'sleepy': 5,\n",
       "         'stupid': 6,\n",
       "         'whether': 11,\n",
       "         'pleasure': 2,\n",
       "         'making': 8,\n",
       "         'daisy': 1,\n",
       "         'chain': 1,\n",
       "         'would': 83,\n",
       "         'be': 148,\n",
       "         'worth': 4,\n",
       "         'trouble': 6,\n",
       "         'getting': 22,\n",
       "         'up': 100,\n",
       "         'picking': 2,\n",
       "         'daisies': 1,\n",
       "         'when': 79,\n",
       "         'suddenly': 13,\n",
       "         'white': 30,\n",
       "         'with': 180,\n",
       "         'pink': 1,\n",
       "         'eyes': 29,\n",
       "         'ran': 16,\n",
       "         'close': 13,\n",
       "         'there': 99,\n",
       "         'remarkable': 2,\n",
       "         'that': 315,\n",
       "         'nor': 3,\n",
       "         'did': 63,\n",
       "         'think': 53,\n",
       "         'much': 51,\n",
       "         'out': 117,\n",
       "         'way': 56,\n",
       "         'hear': 14,\n",
       "         'say': 51,\n",
       "         'itself': 14,\n",
       "         'oh': 45,\n",
       "         'dear': 29,\n",
       "         'shall': 25,\n",
       "         'late': 6,\n",
       "         'over': 40,\n",
       "         'afterwards': 2,\n",
       "         'occurred': 2,\n",
       "         'ought': 14,\n",
       "         'have': 80,\n",
       "         'wondered': 1,\n",
       "         'at': 212,\n",
       "         'this': 134,\n",
       "         'time': 71,\n",
       "         'all': 182,\n",
       "         'seemed': 27,\n",
       "         'quite': 55,\n",
       "         'natural': 4,\n",
       "         'actually': 1,\n",
       "         'took': 24,\n",
       "         'watch': 8,\n",
       "         'its': 57,\n",
       "         'waistcoat': 2,\n",
       "         'pocket': 7,\n",
       "         'looked': 45,\n",
       "         'then': 94,\n",
       "         'hurried': 11,\n",
       "         'started': 2,\n",
       "         'feet': 19,\n",
       "         'flashed': 1,\n",
       "         'across': 5,\n",
       "         'never': 48,\n",
       "         'before': 38,\n",
       "         'seen': 15,\n",
       "         'either': 10,\n",
       "         'take': 22,\n",
       "         'burning': 1,\n",
       "         'curiosity': 5,\n",
       "         'field': 1,\n",
       "         'after': 43,\n",
       "         'fortunately': 1,\n",
       "         'just': 52,\n",
       "         'see': 67,\n",
       "         'pop': 1,\n",
       "         'large': 33,\n",
       "         'under': 16,\n",
       "         'hedge': 2,\n",
       "         'another': 22,\n",
       "         'moment': 31,\n",
       "         'went': 83,\n",
       "         'how': 68,\n",
       "         'world': 7,\n",
       "         'again': 83,\n",
       "         'straight': 2,\n",
       "         'like': 85,\n",
       "         'tunnel': 1,\n",
       "         'some': 51,\n",
       "         'dipped': 2,\n",
       "         'not': 145,\n",
       "         'about': 94,\n",
       "         'stopping': 1,\n",
       "         'herself': 83,\n",
       "         'found': 32,\n",
       "         'falling': 2,\n",
       "         'deep': 7,\n",
       "         'fell': 6,\n",
       "         'slowly': 8,\n",
       "         'plenty': 2,\n",
       "         'look': 29,\n",
       "         'wonder': 18,\n",
       "         'going': 27,\n",
       "         'happen': 8,\n",
       "         'next': 30,\n",
       "         'first': 51,\n",
       "         'tried': 19,\n",
       "         'make': 27,\n",
       "         'coming': 9,\n",
       "         'too': 26,\n",
       "         'dark': 3,\n",
       "         'anything': 20,\n",
       "         'sides': 4,\n",
       "         'noticed': 8,\n",
       "         'they': 152,\n",
       "         'were': 85,\n",
       "         'filled': 3,\n",
       "         'cupboards': 2,\n",
       "         'shelves': 2,\n",
       "         'here': 51,\n",
       "         'saw': 14,\n",
       "         'maps': 1,\n",
       "         'hung': 1,\n",
       "         'upon': 26,\n",
       "         'pegs': 1,\n",
       "         'jar': 2,\n",
       "         'from': 36,\n",
       "         'one': 104,\n",
       "         'passed': 5,\n",
       "         'labelled': 1,\n",
       "         'orange': 1,\n",
       "         'marmalade': 1,\n",
       "         'great': 39,\n",
       "         'disappointment': 1,\n",
       "         'empty': 1,\n",
       "         'drop': 1,\n",
       "         'fear': 4,\n",
       "         'killing': 1,\n",
       "         'somebody': 7,\n",
       "         'managed': 4,\n",
       "         'put': 31,\n",
       "         'past': 3,\n",
       "         'such': 41,\n",
       "         'fall': 7,\n",
       "         'tumbling': 2,\n",
       "         'stairs': 3,\n",
       "         'brave': 1,\n",
       "         'll': 57,\n",
       "         'me': 68,\n",
       "         'home': 5,\n",
       "         'why': 40,\n",
       "         'wouldn': 13,\n",
       "         'even': 19,\n",
       "         'if': 96,\n",
       "         'off': 73,\n",
       "         'top': 8,\n",
       "         'house': 18,\n",
       "         'which': 49,\n",
       "         'likely': 5,\n",
       "         'true': 4,\n",
       "         'come': 46,\n",
       "         'an': 57,\n",
       "         'end': 17,\n",
       "         'many': 12,\n",
       "         'miles': 3,\n",
       "         've': 44,\n",
       "         'fallen': 4,\n",
       "         'said': 462,\n",
       "         'aloud': 5,\n",
       "         'must': 44,\n",
       "         'somewhere': 3,\n",
       "         'near': 15,\n",
       "         'centre': 1,\n",
       "         'earth': 4,\n",
       "         'let': 22,\n",
       "         'four': 8,\n",
       "         'thousand': 2,\n",
       "         'you': 411,\n",
       "         'learnt': 2,\n",
       "         'several': 4,\n",
       "         'things': 31,\n",
       "         'sort': 20,\n",
       "         'lessons': 10,\n",
       "         'schoolroom': 1,\n",
       "         'though': 11,\n",
       "         'good': 27,\n",
       "         'opportunity': 8,\n",
       "         'showing': 2,\n",
       "         'knowledge': 3,\n",
       "         'listen': 7,\n",
       "         'still': 13,\n",
       "         'practice': 1,\n",
       "         'yes': 13,\n",
       "         'right': 32,\n",
       "         'distance': 8,\n",
       "         'latitude': 2,\n",
       "         'longitude': 2,\n",
       "         'got': 45,\n",
       "         'idea': 15,\n",
       "         'nice': 6,\n",
       "         'grand': 3,\n",
       "         'words': 21,\n",
       "         'presently': 2,\n",
       "         'began': 58,\n",
       "         'through': 14,\n",
       "         'funny': 3,\n",
       "         'seem': 8,\n",
       "         'among': 12,\n",
       "         'people': 13,\n",
       "         'walk': 5,\n",
       "         'their': 52,\n",
       "         'heads': 10,\n",
       "         'downward': 1,\n",
       "         'antipathies': 1,\n",
       "         'rather': 25,\n",
       "         'glad': 11,\n",
       "         'listening': 3,\n",
       "         'didn': 14,\n",
       "         'sound': 4,\n",
       "         'word': 10,\n",
       "         'ask': 11,\n",
       "         'them': 88,\n",
       "         'name': 10,\n",
       "         'country': 1,\n",
       "         'know': 88,\n",
       "         'please': 19,\n",
       "         'ma': 3,\n",
       "         'am': 16,\n",
       "         'new': 5,\n",
       "         'zealand': 1,\n",
       "         'australia': 1,\n",
       "         'curtsey': 1,\n",
       "         'spoke': 17,\n",
       "         'fancy': 7,\n",
       "         'curtseying': 1,\n",
       "         're': 38,\n",
       "         'air': 15,\n",
       "         'manage': 7,\n",
       "         'ignorant': 1,\n",
       "         'little': 128,\n",
       "         'girl': 4,\n",
       "         'asking': 5,\n",
       "         'perhaps': 17,\n",
       "         'written': 6,\n",
       "         'else': 12,\n",
       "         'soon': 25,\n",
       "         'talking': 17,\n",
       "         'dinah': 14,\n",
       "         'miss': 4,\n",
       "         'night': 5,\n",
       "         'should': 27,\n",
       "         'cat': 37,\n",
       "         'hope': 3,\n",
       "         'remember': 14,\n",
       "         'saucer': 1,\n",
       "         'milk': 2,\n",
       "         'tea': 19,\n",
       "         'my': 58,\n",
       "         'wish': 21,\n",
       "         'are': 54,\n",
       "         'mice': 4,\n",
       "         'm': 63,\n",
       "         'afraid': 12,\n",
       "         'might': 28,\n",
       "         'catch': 4,\n",
       "         'bat': 3,\n",
       "         'mouse': 44,\n",
       "         'cats': 13,\n",
       "         'eat': 18,\n",
       "         'bats': 4,\n",
       "         'saying': 15,\n",
       "         'dreamy': 1,\n",
       "         'sometimes': 5,\n",
       "         'couldn': 9,\n",
       "         'answer': 9,\n",
       "         'question': 17,\n",
       "         'matter': 9,\n",
       "         'felt': 23,\n",
       "         'dozing': 1,\n",
       "         'begun': 7,\n",
       "         'dream': 7,\n",
       "         'walking': 5,\n",
       "         'hand': 21,\n",
       "         'earnestly': 2,\n",
       "         'now': 60,\n",
       "         'tell': 32,\n",
       "         'truth': 1,\n",
       "         'ever': 21,\n",
       "         'thump': 2,\n",
       "         'came': 40,\n",
       "         'heap': 1,\n",
       "         'sticks': 1,\n",
       "         'dry': 8,\n",
       "         'leaves': 6,\n",
       "         'bit': 16,\n",
       "         'hurt': 3,\n",
       "         'jumped': 6,\n",
       "         'overhead': 1,\n",
       "         'long': 32,\n",
       "         'passage': 4,\n",
       "         'sight': 10,\n",
       "         'hurrying': 1,\n",
       "         'lost': 3,\n",
       "         'away': 25,\n",
       "         'wind': 2,\n",
       "         'turned': 16,\n",
       "         'corner': 4,\n",
       "         'ears': 5,\n",
       "         'whiskers': 3,\n",
       "         'behind': 13,\n",
       "         'longer': 3,\n",
       "         'low': 15,\n",
       "         'hall': 9,\n",
       "         'lit': 1,\n",
       "         'row': 2,\n",
       "         'lamps': 1,\n",
       "         'hanging': 3,\n",
       "         'roof': 6,\n",
       "         'doors': 2,\n",
       "         'round': 41,\n",
       "         'locked': 1,\n",
       "         'been': 38,\n",
       "         'side': 17,\n",
       "         'other': 40,\n",
       "         'trying': 14,\n",
       "         'every': 12,\n",
       "         'door': 30,\n",
       "         'walked': 10,\n",
       "         'sadly': 5,\n",
       "         'middle': 7,\n",
       "         'wondering': 7,\n",
       "         'three': 28,\n",
       "         'legged': 2,\n",
       "         'table': 18,\n",
       "         'solid': 1,\n",
       "         'glass': 10,\n",
       "         'except': 4,\n",
       "         'tiny': 4,\n",
       "         'golden': 7,\n",
       "         'key': 9,\n",
       "         'belong': 1,\n",
       "         'alas': 4,\n",
       "         'locks': 2,\n",
       "         'small': 10,\n",
       "         'any': 39,\n",
       "         'rate': 9,\n",
       "         'open': 7,\n",
       "         'however': 20,\n",
       "         'second': 4,\n",
       "         'curtain': 1,\n",
       "         'fifteen': 1,\n",
       "         'inches': 6,\n",
       "         'high': 16,\n",
       "         'lock': 1,\n",
       "         'delight': 3,\n",
       "         'fitted': 1,\n",
       "         'opened': 10,\n",
       "         'led': 4,\n",
       "         'larger': 7,\n",
       "         'than': 24,\n",
       "         'rat': 1,\n",
       "         'knelt': 1,\n",
       "         'along': 6,\n",
       "         'loveliest': 1,\n",
       "         'garden': 16,\n",
       "         'longed': 2,\n",
       "         'wander': 1,\n",
       "         'those': 10,\n",
       "         'beds': 2,\n",
       "         'bright': 8,\n",
       "         'flowers': 2,\n",
       "         'cool': 2,\n",
       "         'fountains': 2,\n",
       "         'head': 50,\n",
       "         'doorway': 1,\n",
       "         'go': 50,\n",
       "         'poor': 27,\n",
       "         'shoulders': 4,\n",
       "         'shut': 5,\n",
       "         'telescope': 3,\n",
       "         'only': 50,\n",
       "         'begin': 13,\n",
       "         'happened': 7,\n",
       "         'lately': 1,\n",
       "         'few': 9,\n",
       "         'indeed': 16,\n",
       "         'really': 13,\n",
       "         'impossible': 3,\n",
       "         'waiting': 9,\n",
       "         'back': 39,\n",
       "         'half': 23,\n",
       "         'hoping': 3,\n",
       "         'find': 21,\n",
       "         'rules': 3,\n",
       "         'shutting': 2,\n",
       "         'telescopes': 1,\n",
       "         'bottle': 10,\n",
       "         'certainly': 14,\n",
       "         'neck': 7,\n",
       "         'paper': 4,\n",
       "         'label': 2,\n",
       "         'drink': 7,\n",
       "         'beautifully': 2,\n",
       "         'printed': 1,\n",
       "         'letters': 1,\n",
       "         'wise': 2,\n",
       "         'hurry': 11,\n",
       "         'marked': 6,\n",
       "         'poison': 3,\n",
       "         'read': 11,\n",
       "         'histories': 1,\n",
       "         'children': 10,\n",
       "         'who': 63,\n",
       "         'burnt': 1,\n",
       "         'eaten': 1,\n",
       "         'wild': 2,\n",
       "         'beasts': 2,\n",
       "         'unpleasant': 2,\n",
       "         'because': 15,\n",
       "         'simple': 5,\n",
       "         'friends': 2,\n",
       "         'taught': 4,\n",
       "         'red': 3,\n",
       "         'poker': 1,\n",
       "         'will': 33,\n",
       "         'burn': 2,\n",
       "         'hold': 10,\n",
       "         'cut': 5,\n",
       "         'your': 62,\n",
       "         'finger': 5,\n",
       "         'deeply': 4,\n",
       "         'knife': 3,\n",
       "         'usually': 2,\n",
       "         'bleeds': 1,\n",
       "         'forgotten': 6,\n",
       "         'almost': 6,\n",
       "         'certain': 3,\n",
       "         'disagree': 1,\n",
       "         'sooner': 2,\n",
       "         'later': 3,\n",
       "         'ventured': 4,\n",
       "         'taste': 2,\n",
       "         'finding': 3,\n",
       "         'fact': 8,\n",
       "         'mixed': 2,\n",
       "         'flavour': 1,\n",
       "         'cherry': 1,\n",
       "         'tart': 1,\n",
       "         'custard': 1,\n",
       "         'pine': 1,\n",
       "         'apple': 1,\n",
       "         'roast': 1,\n",
       "         'turkey': 1,\n",
       "         'toffee': 1,\n",
       "         'buttered': 1,\n",
       "         'toast': 1,\n",
       "         'finished': 12,\n",
       "         'curious': 19,\n",
       "         'feeling': 7,\n",
       "         'ten': 6,\n",
       "         'face': 15,\n",
       "         'brightened': 2,\n",
       "         'size': 13,\n",
       "         'lovely': 2,\n",
       "         'waited': 11,\n",
       "         'minutes': 11,\n",
       "         'shrink': 1,\n",
       "         'further': 3,\n",
       "         'nervous': 5,\n",
       "         'altogether': 5,\n",
       "         'candle': 3,\n",
       "         'flame': 1,\n",
       "         'blown': 1,\n",
       "         'thing': 49,\n",
       "         'while': 25,\n",
       "         'more': 49,\n",
       "         'decided': 3,\n",
       "         'possibly': 3,\n",
       "         'reach': 4,\n",
       "         'plainly': 1,\n",
       "         'best': 12,\n",
       "         'climb': 1,\n",
       "         'legs': 3,\n",
       "         'slippery': 1,\n",
       "         'sat': 17,\n",
       "         'cried': 20,\n",
       "         'crying': 2,\n",
       "         'sharply': 4,\n",
       "         'advise': 1,\n",
       "         'leave': 9,\n",
       "         'minute': 21,\n",
       "         'generally': 7,\n",
       "         'gave': 15,\n",
       "         'advice': 2,\n",
       "         'seldom': 1,\n",
       "         'followed': 8,\n",
       "         'scolded': 1,\n",
       "         'severely': 4,\n",
       "         'bring': 3,\n",
       "         'tears': 11,\n",
       "         'remembered': 5,\n",
       "         'box': 10,\n",
       "         'cheated': 1,\n",
       "         'game': 13,\n",
       "         'croquet': 9,\n",
       "         'playing': 2,\n",
       "         'against': 9,\n",
       "         'child': 11,\n",
       "         'fond': 4,\n",
       "         'pretending': 1,\n",
       "         'two': 40,\n",
       "         'pretend': 1,\n",
       "         'hardly': 12,\n",
       "         'enough': 18,\n",
       "         'left': 14,\n",
       "         'respectable': 1,\n",
       "         'person': 4,\n",
       "         'eye': 7,\n",
       "         'lying': 8,\n",
       "         'cake': 3,\n",
       "         'currants': 1,\n",
       "         'makes': 11,\n",
       "         'grow': 13,\n",
       "         'can': 63,\n",
       "         'smaller': 3,\n",
       "         'creep': 1,\n",
       "         'don': 61,\n",
       "         'care': 4,\n",
       "         'happens': 5,\n",
       "         'ate': 1,\n",
       "         'anxiously': 14,\n",
       "         'holding': 3,\n",
       "         'growing': 11,\n",
       "         'surprised': 7,\n",
       "         'remained': 3,\n",
       "         'same': 24,\n",
       "         'sure': 24,\n",
       "         'eats': 1,\n",
       "         'expecting': 3,\n",
       "         'dull': 3,\n",
       "         'life': 12,\n",
       "         'common': 1,\n",
       "         'set': 14,\n",
       "         'work': 8,\n",
       "         'ii': 1,\n",
       "         'pool': 11,\n",
       "         'curiouser': 2,\n",
       "         'forgot': 2,\n",
       "         'speak': 15,\n",
       "         'english': 6,\n",
       "         'opening': 3,\n",
       "         'largest': 1,\n",
       "         'bye': 2,\n",
       "         'far': 13,\n",
       "         'shoes': 7,\n",
       "         'stockings': 1,\n",
       "         'dears': 3,\n",
       "         'shan': 6,\n",
       "         'able': 1,\n",
       "         'deal': 12,\n",
       "         'myself': 7,\n",
       "         'kind': 7,\n",
       "         'won': 26,\n",
       "         'want': 9,\n",
       "         'give': 12,\n",
       "         'pair': 5,\n",
       "         'boots': 4,\n",
       "         'christmas': 1,\n",
       "         'planning': 1,\n",
       "         'carrier': 1,\n",
       "         'sending': 2,\n",
       "         'presents': 2,\n",
       "         'odd': 1,\n",
       "         'directions': 3,\n",
       "         'foot': 10,\n",
       "         'esq': 1,\n",
       "         'hearthrug': 1,\n",
       "         'fender': 1,\n",
       "         'love': 3,\n",
       "         'nonsense': 7,\n",
       "         'struck': 2,\n",
       "         'nine': 5,\n",
       "         'hopeless': 1,\n",
       "         'cry': 3,\n",
       "         'ashamed': 2,\n",
       "         'yourself': 10,\n",
       "         'stop': 6,\n",
       "         'shedding': 1,\n",
       "         'gallons': 1,\n",
       "         'until': 5,\n",
       "         'reaching': 1,\n",
       "         'heard': 30,\n",
       "         'pattering': 3,\n",
       "         'hastily': 16,\n",
       "         'dried': 1,\n",
       "         'returning': 1,\n",
       "         'splendidly': 1,\n",
       "         'dressed': 1,\n",
       "         'kid': 5,\n",
       "         'gloves': 11,\n",
       "         'fan': 10,\n",
       "         'he': 125,\n",
       "         'trotting': 2,\n",
       "         'muttering': 3,\n",
       "         'himself': 6,\n",
       "         'duchess': 42,\n",
       "         'savage': 4,\n",
       "         'kept': 13,\n",
       "         'desperate': 1,\n",
       "         'ready': 8,\n",
       "         'help': 9,\n",
       "         'timid': 3,\n",
       "         'voice': 48,\n",
       "         'sir': 7,\n",
       "         'violently': 4,\n",
       "         'dropped': 5,\n",
       "         'skurried': 1,\n",
       "         'darkness': 1,\n",
       "         'hard': 8,\n",
       "         'fanning': 1,\n",
       "         'queer': 12,\n",
       "         'everything': 14,\n",
       "         'yesterday': 3,\n",
       "         'usual': 5,\n",
       "         'changed': 8,\n",
       "         'morning': 5,\n",
       "         'different': 9,\n",
       "         'ah': 5,\n",
       "         'puzzle': 1,\n",
       "         'thinking': 11,\n",
       "         'knew': 14,\n",
       "         'age': 4,\n",
       "         'ada': 1,\n",
       "         'hair': 7,\n",
       "         'goes': 7,\n",
       "         'ringlets': 2,\n",
       "         'mine': 10,\n",
       "         'doesn': 16,\n",
       "         'mabel': 4,\n",
       "         'sorts': 3,\n",
       "         'knows': 2,\n",
       "         'besides': 4,\n",
       "         'puzzling': 4,\n",
       "         'try': 12,\n",
       "         'used': 13,\n",
       "         'times': 6,\n",
       "         'five': 8,\n",
       "         'twelve': 4,\n",
       "         'six': 2,\n",
       "         'thirteen': 1,\n",
       "         'seven': 6,\n",
       "         'twenty': 3,\n",
       "         'multiplication': 1,\n",
       "         'signify': 1,\n",
       "         'geography': 1,\n",
       "         'london': 1,\n",
       "         'capital': 4,\n",
       "         'paris': 2,\n",
       "         'rome': 2,\n",
       "         'wrong': 5,\n",
       "         'doth': 3,\n",
       "         'crossed': 3,\n",
       "         'hands': 12,\n",
       "         'lap': 2,\n",
       "         'repeat': 7,\n",
       "         'sounded': 5,\n",
       "         'hoarse': 3,\n",
       "         'strange': 5,\n",
       "         'crocodile': 1,\n",
       "         'improve': 1,\n",
       "         'his': 96,\n",
       "         'shining': 1,\n",
       "         'tail': 9,\n",
       "         'pour': 1,\n",
       "         'waters': 1,\n",
       "         'nile': 1,\n",
       "         'scale': 1,\n",
       "         'cheerfully': 1,\n",
       "         'seems': 5,\n",
       "         'grin': 6,\n",
       "         'neatly': 2,\n",
       "         'spread': 3,\n",
       "         'claws': 2,\n",
       "         'welcome': 1,\n",
       "         'fishes': 1,\n",
       "         'gently': 3,\n",
       "         'smiling': 2,\n",
       "         'jaws': 2,\n",
       "         'live': 8,\n",
       "         'poky': 1,\n",
       "         'toys': 1,\n",
       "         'play': 8,\n",
       "         'learn': 7,\n",
       "         'stay': 5,\n",
       "         'putting': 3,\n",
       "         'being': 19,\n",
       "         'till': 21,\n",
       "         'sudden': 5,\n",
       "         'burst': 1,\n",
       "         'alone': 4,\n",
       "         'done': 15,\n",
       "         'measure': 1,\n",
       "         'nearly': 11,\n",
       "         'guess': 3,\n",
       "         'shrinking': 4,\n",
       "         'rapidly': 2,\n",
       "         'cause': 3,\n",
       "         'avoid': 1,\n",
       "         'narrow': 2,\n",
       "         'escape': 4,\n",
       "         'frightened': 7,\n",
       "         'change': 14,\n",
       "         'existence': 1,\n",
       "         'speed': 1,\n",
       "         'worse': 3,\n",
       "         'declare': 2,\n",
       "         'bad': 2,\n",
       "         'these': 14,\n",
       "         'slipped': 3,\n",
       "         'splash': 1,\n",
       "         'chin': 7,\n",
       "         'salt': 2,\n",
       "         'water': 5,\n",
       "         'somehow': 1,\n",
       "         'sea': 14,\n",
       "         'case': 5,\n",
       "         'railway': 2,\n",
       "         'seaside': 1,\n",
       "         'general': 3,\n",
       "         'conclusion': 2,\n",
       "         'wherever': 2,\n",
       "         'coast': 1,\n",
       "         'number': 5,\n",
       "         'bathing': 1,\n",
       "         'machines': 1,\n",
       "         'digging': 4,\n",
       "         'sand': 1,\n",
       "         'wooden': 1,\n",
       "         'spades': 1,\n",
       "         'lodging': 1,\n",
       "         'houses': 1,\n",
       "         'station': 1,\n",
       "         'wept': 1,\n",
       "         'hadn': 8,\n",
       "         'swam': 5,\n",
       "         'punished': 1,\n",
       "         'suppose': 14,\n",
       "         'drowned': 1,\n",
       "         'something': 18,\n",
       "         'splashing': 2,\n",
       "         'nearer': 5,\n",
       "         'walrus': 1,\n",
       "         'hippopotamus': 1,\n",
       "         'talk': 14,\n",
       "         'harm': 1,\n",
       "         'o': 6,\n",
       "         'swimming': 2,\n",
       "         'speaking': 5,\n",
       "         'brother': 1,\n",
       "         'latin': 1,\n",
       "         'grammar': 1,\n",
       "         'inquisitively': 1,\n",
       "         'wink': 2,\n",
       "         'understand': 6,\n",
       "         'daresay': 1,\n",
       "         'french': 4,\n",
       "         'william': 8,\n",
       "         'conqueror': 2,\n",
       "         'history': 7,\n",
       "         'clear': 2,\n",
       "         'notion': 3,\n",
       "         'ago': 2,\n",
       "         'ou': 1,\n",
       "         'est': 1,\n",
       "         'chatte': 1,\n",
       "         'sentence': 6,\n",
       "         'lesson': 3,\n",
       "         'leap': 1,\n",
       "         'quiver': 1,\n",
       "         'fright': 2,\n",
       "         'beg': 8,\n",
       "         'pardon': 6,\n",
       "         'animal': 2,\n",
       "         'feelings': 2,\n",
       "         'shrill': 5,\n",
       "         'passionate': 1,\n",
       "         'soothing': 1,\n",
       "         'tone': 40,\n",
       "         'angry': 5,\n",
       "         'yet': 25,\n",
       "         'show': 3,\n",
       "         'our': 8,\n",
       "         'd': 29,\n",
       "         'quiet': 2,\n",
       "         'lazily': 1,\n",
       "         'sits': 1,\n",
       "         'purring': 2,\n",
       "         'nicely': 2,\n",
       "         'fire': 4,\n",
       "         'licking': 1,\n",
       "         'paws': 4,\n",
       "         'washing': 3,\n",
       "         'soft': 1,\n",
       "         'nurse': 3,\n",
       "         'catching': 2,\n",
       "         'bristling': 1,\n",
       "         'offended': 10,\n",
       "         'we': 34,\n",
       "         'trembling': 6,\n",
       "         'subject': 6,\n",
       "         'family': 1,\n",
       "         'always': 13,\n",
       "         'hated': 1,\n",
       "         'nasty': 1,\n",
       "         'vulgar': 1,\n",
       "         'dogs': 3,\n",
       "         'eagerly': 8,\n",
       "         'dog': 3,\n",
       "         'eyed': 1,\n",
       "         'terrier': 1,\n",
       "         'curly': 1,\n",
       "         'brown': 2,\n",
       "         'fetch': 7,\n",
       "         'throw': 3,\n",
       "         'sit': 8,\n",
       "         'dinner': 2,\n",
       "         'belongs': 2,\n",
       "         'farmer': 1,\n",
       "         'says': 4,\n",
       "         'useful': 2,\n",
       "         'hundred': 1,\n",
       "         'pounds': 1,\n",
       "         'kills': 1,\n",
       "         'rats': 1,\n",
       "         'sorrowful': 2,\n",
       "         'commotion': 1,\n",
       "         'called': 15,\n",
       "         'softly': 1,\n",
       "         'pale': 4,\n",
       "         'passion': 3,\n",
       "         'us': 14,\n",
       "         'shore': 4,\n",
       "         'hate': 2,\n",
       "         'crowded': 5,\n",
       "         'birds': 10,\n",
       "         'animals': 4,\n",
       "         'duck': 4,\n",
       "         'dodo': 13,\n",
       "         'lory': 7,\n",
       "         'eaglet': 3,\n",
       "         'creatures': 10,\n",
       "         'whole': 13,\n",
       "         'party': 10,\n",
       "         'iii': 1,\n",
       "         'caucus': 3,\n",
       "         'race': 6,\n",
       "         'tale': 4,\n",
       "         'looking': 32,\n",
       "         'assembled': 2,\n",
       "         'draggled': 1,\n",
       "         'feathers': 1,\n",
       "         'fur': 3,\n",
       "         'clinging': 1,\n",
       "         'dripping': 1,\n",
       "         'wet': 2,\n",
       "         'cross': 3,\n",
       "         'uncomfortable': 4,\n",
       "         'course': 26,\n",
       "         'consultation': 1,\n",
       "         'familiarly': 1,\n",
       "         'known': 1,\n",
       "         'argument': 4,\n",
       "         'last': 33,\n",
       "         'sulky': 3,\n",
       "         'older': 2,\n",
       "         'better': 14,\n",
       "         'allow': 3,\n",
       "         'knowing': 2,\n",
       "         'old': 19,\n",
       "         'positively': 1,\n",
       "         'refused': 1,\n",
       "         'authority': 2,\n",
       "         'ring': 2,\n",
       "         'fixed': 1,\n",
       "         'cold': 1,\n",
       "         'ahem': 1,\n",
       "         'important': 7,\n",
       "         'driest': 1,\n",
       "         'silence': 14,\n",
       "         'whose': 2,\n",
       "         'favoured': 1,\n",
       "         'pope': 1,\n",
       "         'submitted': 1,\n",
       "         'wanted': 4,\n",
       "         'leaders': 1,\n",
       "         'accustomed': 1,\n",
       "         'usurpation': 1,\n",
       "         'conquest': 1,\n",
       "         'edwin': 2,\n",
       "         'morcar': 2,\n",
       "         'earls': 2,\n",
       "         'mercia': 2,\n",
       "         'northumbria': 2,\n",
       "         'ugh': 2,\n",
       "         'shiver': 1,\n",
       "         'frowning': 4,\n",
       "         'politely': 6,\n",
       "         'proceed': 2,\n",
       "         'declared': 1,\n",
       "         'him': 43,\n",
       "         'stigand': 1,\n",
       "         'patriotic': 1,\n",
       "         'archbishop': 2,\n",
       "         'canterbury': 1,\n",
       "         'advisable': 2,\n",
       "         'replied': 29,\n",
       "         'crossly': 1,\n",
       "         'means': 5,\n",
       "         'frog': 3,\n",
       "         'worm': 1,\n",
       "         'notice': 5,\n",
       "         'hurriedly': 2,\n",
       "         'edgar': 1,\n",
       "         'atheling': 1,\n",
       "         'meet': 2,\n",
       "         'offer': 2,\n",
       "         'crown': 3,\n",
       "         'conduct': 1,\n",
       "         'moderate': 1,\n",
       "         'insolence': 1,\n",
       "         'normans': 1,\n",
       "         'continued': 9,\n",
       "         'turning': 12,\n",
       "         'melancholy': 6,\n",
       "         'solemnly': 4,\n",
       "         ...})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts = Counter(carroll_uniq)\n",
    "token_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest, I convert the `Counter` output into a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>the</td>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>and</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>to</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>a</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>it</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index word     n\n",
       "0     11  the  1642\n",
       "1     26  and   872\n",
       "2     16   to   729\n",
       "3     47    a   632\n",
       "4     40   it   595"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = zip(token_counts.keys(), token_counts.values())\n",
    "df = pd.DataFrame(data, columns = ['word', 'n']) \\\n",
    "       .sort_values(by='n', ascending=False) \\\n",
    "       .reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from above there are 26,917 total tokens. So we'll set a cumulative sum on the dataframe and find the closest point to 27,135 / 2 = 13,458:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>n</th>\n",
       "      <th>cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>78</td>\n",
       "      <td>when</td>\n",
       "      <td>79</td>\n",
       "      <td>13459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  word   n  cumsum\n",
       "53     78  when  79   13459"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cumsum'] = df.n.cumsum()\n",
    "df.query('cumsum >= 13400 and cumsum <= 13500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the index, we see that the 53 most frequent tokens make up half of the total corpus length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 200 most frequent tokens\n",
    "\n",
    "Easy to get from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'and',\n",
       " 'to',\n",
       " 'a',\n",
       " 'it',\n",
       " 'she',\n",
       " 'i',\n",
       " 'of',\n",
       " 'said',\n",
       " 'you',\n",
       " 'alice',\n",
       " 'in',\n",
       " 'was',\n",
       " 'that',\n",
       " 'as',\n",
       " 'her',\n",
       " 'at',\n",
       " 'on',\n",
       " 'all',\n",
       " 'with',\n",
       " 'had',\n",
       " 'but',\n",
       " 'for',\n",
       " 'they',\n",
       " 'so',\n",
       " 'be',\n",
       " 'not',\n",
       " 'very',\n",
       " 'what',\n",
       " 'this',\n",
       " 'little',\n",
       " 'he',\n",
       " 'out',\n",
       " 'is',\n",
       " 'one',\n",
       " 'down',\n",
       " 'up',\n",
       " 'there',\n",
       " 'if',\n",
       " 'his',\n",
       " 'about',\n",
       " 'then',\n",
       " 'no',\n",
       " 'them',\n",
       " 'know',\n",
       " 'were',\n",
       " 'like',\n",
       " 'would',\n",
       " 'again',\n",
       " 'went',\n",
       " 'herself',\n",
       " 'do',\n",
       " 'have',\n",
       " 'when',\n",
       " 'or',\n",
       " 'could',\n",
       " 'queen',\n",
       " 'thought',\n",
       " 'off',\n",
       " 'time',\n",
       " 'how',\n",
       " 'me',\n",
       " 'see',\n",
       " 'into',\n",
       " 'king',\n",
       " 'm',\n",
       " 'did',\n",
       " 'well',\n",
       " 'who',\n",
       " 'can',\n",
       " 'your',\n",
       " 'don',\n",
       " 'now',\n",
       " 'turtle',\n",
       " 'by',\n",
       " 'began',\n",
       " 'my',\n",
       " 'its',\n",
       " 'll',\n",
       " 'an',\n",
       " 'mock',\n",
       " 'way',\n",
       " 'hatter',\n",
       " 'quite',\n",
       " 'gryphon',\n",
       " 'are',\n",
       " 'think',\n",
       " 'their',\n",
       " 'just',\n",
       " 'much',\n",
       " 'here',\n",
       " 'rabbit',\n",
       " 'some',\n",
       " 'first',\n",
       " 'say',\n",
       " 'only',\n",
       " 'go',\n",
       " 'head',\n",
       " 'more',\n",
       " 'thing',\n",
       " 'which',\n",
       " 'never',\n",
       " 'voice',\n",
       " 'get',\n",
       " 'come',\n",
       " 'looked',\n",
       " 'got',\n",
       " 'oh',\n",
       " 'must',\n",
       " 've',\n",
       " 'mouse',\n",
       " 'after',\n",
       " 'him',\n",
       " 'duchess',\n",
       " 'such',\n",
       " 'round',\n",
       " 'tone',\n",
       " 'over',\n",
       " 'two',\n",
       " 'dormouse',\n",
       " 'came',\n",
       " 'why',\n",
       " 'other',\n",
       " 'great',\n",
       " 'any',\n",
       " 'back',\n",
       " 'before',\n",
       " 're',\n",
       " 'been',\n",
       " 'cat',\n",
       " 'from',\n",
       " 'we',\n",
       " 'once',\n",
       " 'nothing',\n",
       " 'march',\n",
       " 'will',\n",
       " 'last',\n",
       " 'large',\n",
       " 'looking',\n",
       " 'found',\n",
       " 'tell',\n",
       " 'long',\n",
       " 'right',\n",
       " 'moment',\n",
       " 'put',\n",
       " 'things',\n",
       " 'hare',\n",
       " 'next',\n",
       " 'heard',\n",
       " 'door',\n",
       " 'white',\n",
       " 'made',\n",
       " 'dear',\n",
       " 'look',\n",
       " 'day',\n",
       " 'replied',\n",
       " 'd',\n",
       " 'eyes',\n",
       " 'might',\n",
       " 'three',\n",
       " 'caterpillar',\n",
       " 'poor',\n",
       " 'good',\n",
       " 'make',\n",
       " 'should',\n",
       " 'seemed',\n",
       " 'going',\n",
       " 'upon',\n",
       " 'won',\n",
       " 'too',\n",
       " 'course',\n",
       " 'without',\n",
       " 'yet',\n",
       " 'soon',\n",
       " 'rather',\n",
       " 'shall',\n",
       " 'while',\n",
       " 'away',\n",
       " 'same',\n",
       " 'than',\n",
       " 'sure',\n",
       " 'took',\n",
       " 'half',\n",
       " 'felt',\n",
       " 'added',\n",
       " 'another',\n",
       " 'jury',\n",
       " 'let',\n",
       " 'getting',\n",
       " 'take',\n",
       " 'till',\n",
       " 'hand',\n",
       " 'minute',\n",
       " 'wish',\n",
       " 'ever',\n",
       " 'find',\n",
       " 'words',\n",
       " 'anything',\n",
       " 'cried',\n",
       " 'however']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.word.head(200).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of top 200 words' frequencies\n",
    "\n",
    "This observed frequency does appear to approximate Zipf's law pretty closely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(df.word.head(200).tolist(),\n",
    "        df.n.head(200).tolist())\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('n')\n",
    "plt.title('Top 200 Words in _Alice_')\n",
    "\n",
    "plt.xticks('', '')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference of _Alice_ corpa from all corpus of all words\n",
    "\n",
    "From above the top five words in _Alice_ are 'the', 'and', 'to', 'a', 'it'. This is probably similar to all English-language documents above a certain length. \n",
    "\n",
    "The next most frequent word is 'she', which reflects that the protagonist of this story is female. Other types of texts probably do not have 'she' ranking so highly. Similarly with the token of her name, 'Alice'.\n",
    "\n",
    "'Queen' and 'king' are also very high, as the names of characters in the text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
